
on:
  push:
    branches:
      - '*' # Adjust this to your default branch
  # schedule:
  #   - cron: '0 2 * * *'  # Trigger daily at 2 AM UTC

jobs:
  Continue_pipeline:
    runs-on: self-hosted
    timeout-minutes: 20160  # run for two weeks   , previoulous :  5760  #run is allowed for 4 days max  

    env:
      CONDA: "/home/ubuntu/miniconda3/etc/profile.d/conda.sh"
      CONDA_ENV_NAME: "hadaca3framework_env"
      REPO_DIR: "/home/github-runner/projects/hadaca3_framework/"  # Adjust this to your repo path
      SNK_CORES: "2"
      MEM_MB: "32000"

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      
      - name: Set PAT
        run: echo "GITHUB_PAT=${{ secrets.PAT_CI }}" >> $GITHUB_ENV
    
      - name: Execute commands from README
        run: |
          # echo ${{ github.workspace }}
          cd ${{ env.REPO_DIR }}
          source "${{ env.CONDA }}"
          git fetch --all

          # Sys.setenv(GITHUB_PAT = "${{ secrets.PAT_CI }}")

          git reset --hard ${{ github.sha }}
            awk '/```{Automatic CI-conda}/{f=1; next} f && /```/{f=0; exit} f' README.md | while read -r line; do
            [[ "$line" =~ ^# ]] && continue
            [ -z "$line" ] || [[ "$line" =~ conda\ create ]] && continue
            echo "$line"
            eval "$line"
          done

      # shell: bash
      - name: download data
        run: |
          cd ${{ env.REPO_DIR }}
          mkdir -p data
          cd data
          awk '/```{Automatic CI-data}/{f=1; next} f && /```/{f=0; exit} f && /wget/' ../README.md | while read -r line; do
            echo "$line"
            filename=$(basename "$line")
            if [ ! -f "$filename" ]; then
              echo "Downloading $filename..."
              eval "$line"
            else
              echo "Skipping $filename (already exists)"
            fi
          done
          # cd ${{ env.REPO_DIR }}
          # mkdir -p data
          # cd data
          # awk '/```{Automatic CI-data}/{f=1; next} f && /```/{f=0; exit} f && /wget/' ../README.md | while read -r line; do
          #   echo "$line"
          #   eval "$line"
          # done

      - name: Run pipeline
        # continue-on-error: true  This will not show an error if the pipeline fail  !
        run: |
          cd ${{ env.REPO_DIR }}
          source "${{ env.CONDA }}" 
          conda activate ${{ env.CONDA_ENV_NAME }}
          # git fetch --all
          # git reset --hard ${{ github.sha }}
          # snakemake --cores ${{ env.SNK_CORES }} -s 00_run_pipeline.smk -p clean
          # snakemake --cores ${{ env.SNK_CORES }} -s 00_run_pipeline.smk -p --resources mem_mb=${{ env.MEM_MB }} --max-jobs-per-second 1
          # nextflow run 00_run_pipeline.nf -resume -with-report --setup_folder benchmark/setup/1/
          
          # nextflow run 00_run_pipeline.nf -resume -with-report 

          # Start nextflow in the background and redirect output to log.txt
          rm -f log.txt
          rm -r 08_metaanalysis_files
          rm -r 08_metaanalysis.html
          rm -r 07_metaanalysis_files
          rm -r 07_metaanalysis.html

          nextflow run 00_run_pipeline.nf -resume -with-report > log.txt 2>&1 &

          # Save the PID of the background job
          PIPELINE_PID=$!

          echo "Nextflow pipeline started with PID $PIPELINE_PID"

          # Periodically print the last 10 lines of the log
          while kill -0 "$PIPELINE_PID" 2>/dev/null; do
            echo "===== Log snapshot at $(date) ====="
            tail -n 15 log.txt
            echo ""
            sleep 300  # Wait for 5 minutes
          done

          # Wait for nextflow to finish to capture the final exit status
          wait $PIPELINE_PID
          EXIT_CODE=$?

          echo "Nextflow pipeline finished with exit code $EXIT_CODE"
          
          mkdir -p ${{ github.workspace }}/public
          cp 07_prep_metaanalysis.html ${{ github.workspace }}/public/prep_metaanalysis.html
          cp -R 07_prep_metaanalysis_files   ${{ github.workspace }}/public/07_prep_metaanalysis_files
          cp 08_metaanalysis.html ${{ github.workspace }}/public/metaanalysis.html
          cp -R 08_metaanalysis_files ${{ github.workspace }}/public/08_metaanalysis_files
          LATEST_REPORT=$(ls -t report-* | head -n 1)
          cp $LATEST_REPORT ${{ github.workspace }}/public/nextflow-report.html
          cp index.html ${{ github.workspace }}/public/
          cp results_li.csv.gz ${{ github.workspace }}/public/
          cp results_ei.csv.gz ${{ github.workspace }}/public/
          exit $EXIT_CODE

      - name : copy report if failure 
        if : failure()  # always() always will run even if cancelled manually   #failure()
        run : |
          cd ${{ env.REPO_DIR }}
          echo "===== Log failled snapshot at $(date) ====="
          tail -n 200 log.txt

      # - name : copy report if failure 
      #   if : failure()  # always() always will run even if cancelled manually   #failure()
      #   run : |
      #     cd ${{ env.REPO_DIR }}
      #     # this will still copy the last metaanalysis
      #     mkdir -p ${{ github.workspace }}/public
      #     cp 07_metaanalysis.html ${{ github.workspace }}/public/metaanalysis.html
      #     cp -R 07_prep_metaanalysis_files   ${{ github.workspace }}/public/07_prep_metaanalysis_files
      #     LATEST_REPORT=$(ls -t report-* | head -n 1)
      #     cp $LATEST_REPORT ${{ github.workspace }}/public/nextflow-report.html
      #     cp index.html ${{ github.workspace }}/public/
      #     cp results_li.csv ${{ github.workspace }}/public/
      #     cp results_ei.csv ${{ github.workspace }}/public/
      #     ls -la ${{ github.workspace }}/public

      # name: 
      # - name: Check for errors and read logs 
      #   if: failure()
      #   run: |
      #     echo "An error occurred. Checking log files for details..."
      #     LOG_DIR=".snakemake/log/"

      #     # Find the latest log file
      #     LATEST_LOG=$(ls -t "$LOG_DIR" | head -n 1)

      #     # Check if a log file was found
      #     if [ -z "$LATEST_LOG" ]; then
      #       echo "No log files found in the directory."
      #       exit 1
      #     fi
      #     echo $LOG_DIR$LATEST_LOG
      #     ERROR_LOGS=$(grep -A 5 "Error in rule" "$LOG_DIR$LATEST_LOG" | grep -oP 'log: \K.*?(?= \(check log file)')
      #     echo $ERROR_LOGS
      #     if [ -z "$ERROR_LOGS" ]; then
      #       echo "No error logs found in Snakemake log."
      #       exit 0
      #     fi

      #     # Display the contents of the error logs
      #     echo "Errors found in the following log files:"
      #     for LOG_FILE in $ERROR_LOGS; do
      #       echo "--- $LOG_FILE ---"
      #       if [ -f "$LOG_FILE" ]; then
      #         cat "$LOG_FILE"
      #       else
      #         echo "Log file not found: $LOG_FILE"
      #       fi
      #     done

      - name: Deploy to GitHub Pages
        if: success() || failure() 
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public

